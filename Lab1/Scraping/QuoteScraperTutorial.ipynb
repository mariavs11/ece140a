{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7rKAKzDP_LS"
   },
   "source": [
    "# Tutorial: Web Scraping using BeautifulSoup\n",
    "\n",
    "## Introduction\n",
    "Web scraping is a technique that uses the HTML structure of a webpage to extract useful information. This is very useful to automate web related tasks that have a fixed structure. In this notebook we will be extracting quotes and their authors from this website: http://quotes.toscrape.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKYfTKeVP_LV"
   },
   "source": [
    "### Importing Libraries\n",
    "\n",
    "We will import the following libraries for scraping the webpage:\n",
    "1. **requests**: Used for basic get, post operations to the webpage. Here, to get the data from quotes.toscrape.com's servers\n",
    "2. **bs4** (BeautifulSoup): To extract the content based on html tags and their attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q24pmkFIP_LY"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7B-zKHnP_Lj"
   },
   "source": [
    "Defining two variables for user input:\n",
    "1. tag (the HTML tag to search for in a quote)\n",
    "2. index (the location number of the quote that we want to extract)\n",
    "\n",
    "We define `modindex = index-1` as the modified index because indexing starts from 0 in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fm0QdWDyP_Lm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag = input(\"Enter the tag for which you want to find quotes: \")\n",
    "index = int(input(\"Enter which quote to show: \"))\n",
    "modindex = index-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfUsEQG_P_Lu"
   },
   "source": [
    "### Getting the required pages\n",
    "Web scraping requires a great deal of understanding on how a particular webpage is created and less about the actual scraping process. We need to know the URL structure, the tags/ids/classes used for the information of relevance, etc.\n",
    "\n",
    "Let's have a look at the quotes webpage. If you look at the page's source, you will see that every quote tag URL is of the form <b>http://quotes.toscrape.com/tag/[tag_name]/page/[1or2]/ </b> and by observation we see that each page contains a maximum of 10 quotes. Using this information, we can get the HTML content of the page by using the method: `requests.get()`. You will learn about web requests in the coming week.\n",
    "\n",
    "For now, note that the `request.get()` method gets a response object returned by the server based on the given URL. Based on the response, we can extract its content using bs4 and create what is generally called a `soup`.\n",
    "The `soup.prettify()` method prettifies the extracted HTML content in the soup so that it is clearly legible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ccUlIgqP_Lv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generating URL of interest\n",
    "\n",
    "page = str((modindex//10)+1)\n",
    "url = \"http://quotes.toscrape.com/tag/\"+tag+\"/page/\"+page+\"/\"\n",
    "print(\"URL:\", url)\n",
    "\n",
    "# You can open this URL in your browser to check if the link opens to a valid page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utppFMXMvD0v"
   },
   "outputs": [],
   "source": [
    "# Extracting the contents of the webpage to a soup\n",
    "r = requests.get(url)\n",
    "c = r.content\n",
    "soup = BeautifulSoup(c,\"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sI7b07tIvqSF"
   },
   "source": [
    "**Question**: Print the soup variable as is and print soup.prettify, what difference do you see?\n",
    "By printing soup.prettify, we see a difference with how the html code is presented in that the code is now idented and easy to interpret. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bey5MI5iP_L1"
   },
   "source": [
    "Now that we have the HTML content, observe that all the data relevant to quotes is in a `span` tag and has an attribute, 'class' as `text`. The `find_all()` method for the soup object is used here to get all such occurences. It gives us the list of all occurences of the query, here quotes. We store the list in variable `text`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1XHTb4IP_L3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = soup.find_all('span',class_=\"text\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fX7xEGDEP_L-"
   },
   "source": [
    "Hence here we can see all the quotes relevent to input tags are stored in the list <b>text</b>\n",
    "to access the desired quote (nth quote):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCzzwhUFP_MA"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  print(text[modindex%10].text)\n",
    "except:\n",
    "  print('quote not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8SjMz3vP_MI"
   },
   "source": [
    "Similarly, to find the author's name, we find the tag `small` and class `author`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FD6UmqwRP_MK"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    au = soup.find_all('small',class_=\"author\")\n",
    "    print(\"by\",au[modindex%10].text)\n",
    "except:\n",
    "    print(\"quote not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEhDuAJG9AJz"
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Using BeautifulSoup, we have shown how to scrape data and extract useful information from the webpages. There are many applications to scraping which you can explore in your free time! Good job!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "QuoteScraperTutorial.ipynb",
   "provenance": [
    {
     "file_id": "1fq_5wH7HwS7aRyajwAHecP8ocza2zxoU",
     "timestamp": 1640655381398
    },
    {
     "file_id": "11T1rNazQIP4rmlAh1cYbxiO-rjh1X-V5",
     "timestamp": 1640655301207
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
